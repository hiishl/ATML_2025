{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Markov Decision Processes (MDPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we consider some tasks and check if/how they can be formulated as Markov Decision Processes (MDPs).\n",
    "Recall that a Markov Decision Process (MDP) is a tuple $(S, A, R, P, \\gamma)$ where:\n",
    "- $S$ is the state space,\n",
    "- $A$ is the action space,\n",
    "- $R$ is the set of possible rewards,\n",
    "- $P$ is the transition matrix,\n",
    "- $\\gamma$ is the discount factor.\n",
    "\n",
    "Usually, the sets $S$, $A$, and $R$ can be described conscisely using set notation, while the transition matrix $P$ is the most complex part to define.\n",
    "\n",
    "Furthermore, it is useful to identify the terminal state(s), and whether the MDP is episodic or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridworld\n",
    "\n",
    "E.g. module 1, slide 27.\n",
    "- $S = \\{(i, j) \\mid i = 1, \\ldots, n; j = 1, \\ldots, m\\} \\equiv \\{1, \\dots, nm\\}$,\n",
    "    possibly with some squares removed (obstacles, etc.) and one (or more) terminal states.\n",
    "- $A = \\{U, D, R, L\\} \\equiv \\{(1,0), (-1,0), (0,1), (0,-1)\\} \\equiv \\{1, 2, 3, 4\\}$,\n",
    "    or restricted to \"possible moves\" $A(s)$ in each state $s$.\n",
    "- $R = \\{-1, 0, 5, 10\\} \\subset \\mathbb{R}$.\n",
    "- $\\gamma = 0.9$ (or any other value in $(0, 1)$).\n",
    "\n",
    "Writing down the transition matrix $p(s', r | s, a)$ explicitly requires stating\n",
    "$|S| \\times |R| \\times |S| \\times |A|$ probabilities, which is usually not feasible.\n",
    "E.g., in the $4 \\times 4$ gridworld, we need to write down $16 \\times 4 \\times 16 \\times 4 = 4096$ probabilities,\n",
    "most of which would be zero.\n",
    "\n",
    "Given the deterministic structure of this particular gridworld, we can define the transition matrix $P$ implicitly, e.g.,\n",
    "by defining a function $(s', r) = f(s, a)$ that returns the next state and reward given the current state and action.\n",
    "\n",
    "Depending on the existence of terminal states, this MDP can be episodic or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maze Solving\n",
    "\n",
    "Basically the same as Gridworld, but with a clearly defined goal state, which should be reached as fast as possible.\n",
    "Reward structure could be\n",
    "- $R = \\{0, 1\\}$, where $1$ is the reward for reaching the goal state, and $0$ otherwise.\n",
    "    In this case a discount factor $\\gamma < 1$ is required.\n",
    "- $R = \\{-1, 0\\}$, where $-1$ is the reward for each step, and $0$ for reaching the goal state.\n",
    "    In this case a discount factor $\\gamma = 1$ can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Blackjack\n",
    "\n",
    "As on [Wikipedia](https://en.wikipedia.org/wiki/Blackjack),\n",
    "but considering only without betting and splitting.\n",
    "Consider only a single player and draw cards with replacement.\n",
    "\n",
    "- $S = \\{1, \\ldots, 21\\} \\times \\{1, \\ldots, 10\\} \\times \\{1, 2\\}$,\n",
    "    where the first component is the player's sum, the second is the dealer's showing card, and the third is the player's usable ace.\n",
    "- $A = \\{\\text{hit}, \\text{stick}\\}$.\n",
    "- $R = \\{-1, 0, 1\\}$.\n",
    "- $\\gamma = 1$.\n",
    "\n",
    "The transition probabilities for the \"hit\" action are quite easy to express,\n",
    "as they simply add a card to the player's sum,\n",
    "possibly going bust or changing the usable ace status.\n",
    "Similarly, the \"stick\" action always ends the round, i.e.,\n",
    "leading to the terminal state.\n",
    "Here, only the probability of a win or loss needs to be computed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tic Tac Toe\n",
    "Consider the opponent as part of the environment,\n",
    "having a stationary, possibly random, policy.\n",
    "\n",
    "- $S \\subset \\{0, 1, 2\\}^9$, indicating empty squares ($0$) or marked squares ($1, 2$).\n",
    "    The exact set set of possible states is harder to describe (balanced player marks, no impossible multiple winning combinations).\n",
    "- $A = \\{1, \\ldots, 9\\}$, indicating the square to mark, or $A(s) = \\{1, \\ldots, 9\\} \\setminus \\{s_i \\mid s_i \\neq 0\\}$.\n",
    "- $R = \\{-1, 0, 1\\}$, indicating loss, draw, or win.\n",
    "- $\\gamma = 1$.\n",
    "\n",
    "Transitions consist of two steps. First, the selected square is marked, deterministically,\n",
    "and then the opponent marks a square, according to their policy.\n",
    "Non-zero rewards are only given at the end of the game, i.e., in terminal states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Controling a Simulated Vehicle in 2d Space\n",
    "\n",
    "(No unique solution, many formulations possible)\n",
    "\n",
    "- $S = \\mathbb{R}^2 \\times \\mathbb{R}^2$,\n",
    "    where the first component is the position, the second is the velocity.\n",
    "- $A = \\mathbb{R}^2$,\n",
    "    where the first component is the acceleration in the $x$ direction, the second is the acceleration in the $y$ direction.\n",
    "- $R = \\mathbb{R}$. The rewards should reflect all relevant criteria, e.g., energy consumption, time, comfort, reaching a goal, etc.\n",
    "- $\\gamma$ must be chosen according to the task. Usually $\\gamma<1$ if the task is continuous, $\\gamma=1$ if the task is episodic.\n",
    "\n",
    "Transition probabilities can be very complex, depending on the physics model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Trading\n",
    "\n",
    "We require discrete time steps, e.g., one day, and a fixed set of $d$ stocks.\n",
    "\n",
    "- $S \\subset \\mathbb{R}^d \\cup \\mathbb{R}^D$,\n",
    "    where the first $d$ components are the amount of each stock held, and the next $D$ components are all available information (e.g., stock prices).\n",
    "- $A = \\mathbb{R}^d$,\n",
    "    where the $i$-th component is the amount of stock $i$ to buy or sell.\n",
    "- $R = \\mathbb{R}$. The rewards could simply be returns, or more complex, taking into account transaction costs or risk aversion.\n",
    "- $\\gamma$ could represent the market interest rate\n",
    "\n",
    "Transition probabilities are complex, depending on the stock market model used."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
